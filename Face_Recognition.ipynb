{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YosefAshraf24/Face-Recognition/blob/main/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhMDgVtafqep"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yV9I0gCFsau"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import hashlib\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import linalg as la\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA as SKLPCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nLUYH2Wfqew"
      },
      "source": [
        "# Load ORL Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7ebvMzKfqex"
      },
      "source": [
        "## Load Data and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgLZ7bPP79iG"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "  \"\"\"\n",
        "  Loads a dataset from a given path.\n",
        "\n",
        "  Args:\n",
        "    path: Path to the dataset\n",
        "\n",
        "  Returns:\n",
        "    data: A matrix of shape (num_samples, num_features) containing the data\n",
        "    labels: A vector of shape (num_samples) containing the label for each sample\n",
        "  \"\"\"\n",
        "  # Initialize data matrix and labels vector\n",
        "  data = np.empty((0, 10304), dtype=np.uint8)\n",
        "  labels = np.empty((0), dtype=np.uint8)\n",
        "  \n",
        "  # Get all possible labels from the folder names\n",
        "  # A folder called \"s1\" corresponds to label 1, \"s2\" to label 2, etc.\n",
        "  unique_labels = os.listdir(path)\n",
        "  unique_labels = map(lambda x: int(x[1:]), unique_labels)\n",
        "  unique_labels = sorted(unique_labels)\n",
        "  unique_labels = np.array(unique_labels)\n",
        "\n",
        "  # Loop through all labels\n",
        "  for label in unique_labels:\n",
        "    # Loop through all images labeled with the current label\n",
        "    label_path = os.path.join(path, \"s\" + str(label))\n",
        "    image_names = os.listdir(label_path)\n",
        "    image_names = sorted(image_names, key=lambda x: int(x[:-4]))\n",
        "    for image_name in image_names:\n",
        "      # Read in the image and convert to grayscale\n",
        "      image_path = os.path.join(label_path, image_name)\n",
        "      image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "      # Downscale the image to 112x92 and flatten it into a vector\n",
        "      image = cv.resize(image, (112, 92))\n",
        "      image = image.flatten()\n",
        "\n",
        "      # Add collected data\n",
        "      data = np.append(data, np.array([image]), axis=0)\n",
        "      labels = np.append(labels, np.array([label]), axis=0)\n",
        "\n",
        "  # Print some information about the dataset\n",
        "  print(f\"Dataset: {path}\")\n",
        "  print(f\"  - Number of samples: {data.shape[0]}\")\n",
        "  print(f\"  - Number of features: {data.shape[1]}\")\n",
        "  print(f\"  - Number of unique labels: {unique_labels.shape[0]}\")\n",
        "  print()\n",
        "\n",
        "  return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ16wQOifqez"
      },
      "outputs": [],
      "source": [
        "data, labels = load_data('./archive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVnfyalSfqez"
      },
      "source": [
        "## Split the Dataset into Training and Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urwmav1kfqe0"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets with a 1:1 ratio\n",
        "training_data = data[1::2]\n",
        "training_labels = labels[1::2]\n",
        "testing_data = data[::2]\n",
        "testing_labels = labels[::2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M7RUJYEfqe1"
      },
      "source": [
        "## Plot a Random Sample From the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnEMKAwZfqe2"
      },
      "outputs": [],
      "source": [
        "def plot_images_samples(data, labels, num_samples=5):\n",
        "  \"\"\"\n",
        "  Plots a random sample of images from a dataset.\n",
        "\n",
        "  Args:\n",
        "    data: A matrix of shape (num_samples, num_features) containing the data\n",
        "    labels: A vector of shape (num_samples) containing the label for each sample\n",
        "    num_samples: The number of images to plot for each label (default: 5)\n",
        "\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  # Get the unique labels and their cound\n",
        "  unique_labels = np.unique(labels)\n",
        "  num_labels = len(unique_labels)\n",
        "\n",
        "  # Initialize the figure where we will plot the images\n",
        "  _, axs = plt.subplots(num_labels, num_samples, figsize=(num_samples, num_labels))\n",
        "\n",
        "  # Loop through all available labels\n",
        "  for i, label in enumerate(unique_labels):\n",
        "    # Choose a random sample of images for the current label\n",
        "    label_indices = np.where(labels == label)[0]\n",
        "    label_indices = np.random.choice(label_indices, num_samples, replace=False)\n",
        "\n",
        "    # Loop through all images in the sample\n",
        "    for j, index in enumerate(label_indices):\n",
        "      # Plot the image\n",
        "      image = data[index].reshape((92, 112))\n",
        "      axs[i, j].imshow(image, cmap='gray')\n",
        "      axs[i, j].axis('off')\n",
        "      axs[i, j].set_title(label)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRjhb19Pfqe3"
      },
      "outputs": [],
      "source": [
        "print(\"A sample of images from the training set:\")\n",
        "plot_images_samples(training_data, training_labels)\n",
        "\n",
        "print(\"A sample of images from the testing set:\")\n",
        "plot_images_samples(testing_data, testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xXuXS48TQPI"
      },
      "source": [
        "# Classification Using PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p6CfRlqfqe3"
      },
      "source": [
        "## Algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4IEJR-eJOR_"
      },
      "outputs": [],
      "source": [
        "def pca(data, alphas=[0.8, 0.85, 0.9, 0.95]):\n",
        "  \"\"\"\n",
        "  Performs PCA on the given dataset.\n",
        "\n",
        "  Args:\n",
        "    data: A matrix of shape (num_samples, num_features) containing the data\n",
        "    alphas: A list of floats between 0 and 1 indicating the variance to be explained\n",
        "        by the PCA projection (default: [0.8, 0.85, 0.9, 0.95])\n",
        "\n",
        "  Returns:\n",
        "    proj_matrices: A list of projection matrices, one for each alpha\n",
        "  \"\"\"\n",
        "  # Initialize the list of projection matrices\n",
        "  proj_matrices = [None] * len(alphas)\n",
        "\n",
        "  # Initialize eigenvectors and eigenvalues\n",
        "  eig_vecs = None\n",
        "  eig_vals = None\n",
        "\n",
        "  # Get sha1 hash of the data\n",
        "  hash = hashlib.sha1()\n",
        "  hash.update(data.tobytes())\n",
        "  hash = hash.hexdigest()\n",
        "\n",
        "  # Check if the eigenvectors are cached\n",
        "  if os.path.exists(f\"./.cache/pca_{hash}.npz\"):\n",
        "    container = np.load(f\"./.cache/pca_{hash}.npz\")\n",
        "    eig_vecs = container['arr_0']\n",
        "    eig_vals = container['arr_1']\n",
        "    del container\n",
        "  else:\n",
        "    # Compute the overall mean\n",
        "    data_mean = np.mean(data, axis=0)\n",
        "\n",
        "    # Center the data\n",
        "    data_centered = data - data_mean\n",
        "\n",
        "    # Compute the covariance matrix\n",
        "    cov_mat = np.cov(data_centered, rowvar=False)\n",
        "\n",
        "    # Calculate the eigenvectors and eigenvalues\n",
        "    eig_vals, eig_vecs = la.eigh(cov_mat)\n",
        "\n",
        "    # Sort the eigenvectors and eigenvalues in descending order\n",
        "    idx = eig_vals.argsort()[::-1]\n",
        "    eig_vals = eig_vals[idx]\n",
        "    eig_vecs = eig_vecs[:, idx]\n",
        "\n",
        "    # Cache the eigenvectors and eigenvalues\n",
        "    if not os.path.exists(\"./.cache\"):\n",
        "        os.makedirs(\"./.cache\")\n",
        "    np.savez(f\"./.cache/pca_{hash}.npz\", eig_vecs, eig_vals)\n",
        "\n",
        "  # Compute the cumulative explained variance\n",
        "  cumulative_explained_variance = np.cumsum(eig_vals) / np.sum(eig_vals)\n",
        "  \n",
        "  # Find the least number of eigenvectors needed to explain the variance for each alpha\n",
        "  for i, alpha in enumerate(alphas):\n",
        "    num_eig = np.argmax(cumulative_explained_variance >= alpha) + 1\n",
        "    proj_matrices[i] = eig_vecs[:, :num_eig]\n",
        "  return proj_matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MltpfBDfqe4"
      },
      "source": [
        "## Run the Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_Hmluukfqe5"
      },
      "outputs": [],
      "source": [
        "# Initialize the list of alpha values\n",
        "alphas = [0.8, 0.85, 0.9, 0.95]\n",
        "\n",
        "# Compute the projection matrices for each alpha\n",
        "proj_matrices = pca(training_data, alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jiQqvnpfqe5"
      },
      "source": [
        "## Evaluate the Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m16oyoHNfqe5"
      },
      "outputs": [],
      "source": [
        "def plot_failed_predictions(data, labels, predictions):\n",
        "    \"\"\"\n",
        "    Plots the images that are wrongly classified by a classifier.\n",
        "\n",
        "    An example of each wrong class is also plotted.\n",
        "\n",
        "    Args:\n",
        "        data: A matrix of shape (num_samples, num_features) containing the data\n",
        "            whose labels was predicted by the classifier.\n",
        "        labels: A vector of shape (num_samples,) containing the true labels of the data.\n",
        "        predictions: A vector of shape (num_samples,) containing the predicted labels of the data.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Find the indices of the failed predictions\n",
        "    failed_predictions = np.where(predictions != labels)[0]\n",
        "\n",
        "    # Find the predicted classes of the failed predictions\n",
        "    wrong_classes = predictions[failed_predictions]\n",
        "\n",
        "    # Find the images that are wrongly classified\n",
        "    missed_images = data[failed_predictions]\n",
        "\n",
        "    # Get an example of each wrong class\n",
        "    wrong_images = [data[np.where(testing_labels == i)[0][0]] for i in wrong_classes]\n",
        "\n",
        "    # Plot the images in two columns\n",
        "    fig, axs = plt.subplots(len(failed_predictions), 2, figsize=(6, len(failed_predictions) * 2.5))\n",
        "    fig.suptitle(f\"{len(failed_predictions)}/{len(predictions)} Failed Predictions\")\n",
        "    fig.subplots_adjust(top=0.94)\n",
        "    for i in range(len(failed_predictions)):\n",
        "        axs[i, 0].set_title(f\"Right class: {labels[failed_predictions[i]]}\")\n",
        "        axs[i, 0].imshow(missed_images[i].reshape(92, 112), cmap='gray')\n",
        "        axs[i, 1].set_title(f\"Predicted class: {wrong_classes[i]}\")\n",
        "        axs[i, 1].imshow(wrong_images[i].reshape(92, 112), cmap='gray')\n",
        "\n",
        "    # turn off the axis\n",
        "    for ax in axs.flat:\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imATx-bVfqe6"
      },
      "outputs": [],
      "source": [
        "def plot_failed_xy_predictions(data, labels, predictions):\n",
        "    \"\"\"\n",
        "    Plots the images that are wrongly classified by a T/F classifier.\n",
        "\n",
        "    Args:\n",
        "        data: A matrix of shape (num_samples, num_features) containing the data\n",
        "            whose labels was predicted by the classifier.\n",
        "        labels: A vector of shape (num_samples,) containing the true labels of the data.\n",
        "        predictions: A vector of shape (num_samples,) containing the predicted labels of the data.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Find the indices of the failed predictions\n",
        "    failed_predictions = np.where(predictions != labels)[0]\n",
        "\n",
        "    # Find the images that are wrongly classified\n",
        "    missed_images = data[failed_predictions]\n",
        "\n",
        "    # Plot the images\n",
        "    fig, axs = plt.subplots(math.ceil(len(failed_predictions) / 4), 4, figsize=(10, math.ceil(len(failed_predictions) / 4) * 2))\n",
        "    fig.suptitle(f\"{len(failed_predictions)}/{len(predictions)} Failed Predictions\")\n",
        "    fig.subplots_adjust(top=0.94)\n",
        "    row = 0\n",
        "    col = 0\n",
        "    for i in range(len(failed_predictions)):\n",
        "        axs[row, col].imshow(missed_images[i].reshape(92, 112), cmap='gray')\n",
        "        col = (col + 1) % 4\n",
        "        row = row + 1 if col == 0 else row\n",
        "\n",
        "    # turn off the axis\n",
        "    for ax in axs.flat:\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nT_QWa2fqe7"
      },
      "outputs": [],
      "source": [
        "def plot_success_xy_predictions(data, labels, predictions):\n",
        "    \"\"\"\n",
        "    Plots the images that are correctly classified by a T/F classifier.\n",
        "\n",
        "    Args:\n",
        "        data: A matrix of shape (num_samples, num_features) containing the data\n",
        "            whose labels was predicted by the classifier.\n",
        "        labels: A vector of shape (num_samples,) containing the true labels of the data.\n",
        "        predictions: A vector of shape (num_samples,) containing the predicted labels of the data.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Find the indices of the failed predictions\n",
        "    correct_predictions = np.where(predictions == labels)[0]\n",
        "\n",
        "    # Find the images that are wrongly classified\n",
        "    found_images = testing_data[correct_predictions]\n",
        "\n",
        "    # Plot the images\n",
        "    fig, axs = plt.subplots(math.ceil(len(correct_predictions) / 20), 20, figsize=(10, math.ceil(len(correct_predictions) / 20) * 0.5))\n",
        "    fig.suptitle(f\"{len(correct_predictions)}/{len(predictions)} Correct Predictions\")\n",
        "    fig.subplots_adjust(top=0.9)\n",
        "    row = 0\n",
        "    col = 0\n",
        "    for i in range(len(correct_predictions)):\n",
        "        axs[row, col].imshow(found_images[i].reshape(92, 112), cmap='gray')\n",
        "        col = (col + 1) % 20\n",
        "        row = row + 1 if col == 0 else row\n",
        "\n",
        "    # turn off the axis\n",
        "    for ax in axs.flat:\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3fGzVoNfqe8"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(\n",
        "    proj_matrix,\n",
        "    training_data,\n",
        "    training_labels,\n",
        "    testing_data,\n",
        "    testing_labels,\n",
        "    ks=[1, 3, 5, 7]\n",
        "):\n",
        "  \"\"\"\"\n",
        "  Evaluates the performance of a k-NN classifier on the given data.\n",
        "\n",
        "  Args:\n",
        "      training_data: A matrix of shape (num_training_samples, num_features) containing the training data.\n",
        "      training_labels: A vector of shape (num_training_samples,) containing the training labels.\n",
        "      testing_data: A matrix of shape (num_testing_samples, num_features) containing the testing data.\n",
        "      testing_labels: A vector of shape (num_testing_samples,) containing the testing labels.\n",
        "      ks: A list of k values to use for the k-NN classifier.\n",
        "\n",
        "  Returns:\n",
        "      best: The best accuracy achieved by the k-NN classifier.\n",
        "  \"\"\"\n",
        "  # Initialize the best accuracy and the list of accuracies for each k\n",
        "  best = 0\n",
        "  res = [None] * len(ks)\n",
        "\n",
        "  # Check if classification is binary\n",
        "  is_xy = np.unique(training_labels).shape[0] == 2\n",
        "\n",
        "  # Project the data onto the subspace spanned by the projection matrix\n",
        "  proj_trainning_data = np.dot(training_data, proj_matrix)\n",
        "  proj_testing_data = np.dot(testing_data, proj_matrix)\n",
        "\n",
        "  # Loop over each k\n",
        "  for i, k in enumerate(ks):\n",
        "    # Train the classifier and predict the labels\n",
        "    neigh = KNeighborsClassifier(n_neighbors=k).fit(proj_trainning_data, training_labels)\n",
        "    predictions = neigh.predict(proj_testing_data)\n",
        "\n",
        "    # Compute the accuracy and update the best accuracy\n",
        "    res[i] = np.mean(predictions == testing_labels)\n",
        "    best = max(best, res[i])\n",
        "    print(f\"@nn = {k}, accuracy = {res[i]}\")\n",
        "\n",
        "    # Plot the images that are correctly and incorrectly classified if the\n",
        "    # classification is binary. Otherwise, plot the incorrectly classified images only.\n",
        "    if is_xy:\n",
        "      plot_failed_xy_predictions(testing_data, testing_labels, predictions)\n",
        "      plot_success_xy_predictions(testing_data, testing_labels, predictions)\n",
        "    else:\n",
        "      plot_failed_predictions(testing_data, testing_labels, predictions)\n",
        "\n",
        "  # Plot the relationship between k and accuracy\n",
        "  plt.plot(ks, res)\n",
        "  plt.title('Accuracy of KNN classifier with LDA')\n",
        "  plt.gcf().set_size_inches(15,5)\n",
        "  plt.xlabel('K')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.show()\n",
        "  return best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu4EzH8dfqe8"
      },
      "outputs": [],
      "source": [
        "# Evaluate the performance of the k-NN classifier for each alpha\n",
        "for i in range(len(alphas)):\n",
        "  print(f\"Evaluating model with alpha = {alphas[i]}:\")\n",
        "  evaluate_model(proj_matrices[i], training_data, training_labels, testing_data, testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uazPZX1Gfqe9"
      },
      "source": [
        "# Classification Using LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmPadu29fqe9"
      },
      "source": [
        "## Algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLd2-VMSfqe9"
      },
      "outputs": [],
      "source": [
        "def lda(data, labels, eigc=None):\n",
        "    \"\"\"\"\n",
        "    Performs Linear Discriminant Analysis on the given data.\n",
        "\n",
        "    Args:\n",
        "        data: A matrix of shape (num_samples, num_features) containing the data.\n",
        "        labels: A vector of shape (num_samples,) containing the labels of the data.\n",
        "        eigc: The number of eigenvectors to use for the projection matrix.\n",
        "\n",
        "    Returns:\n",
        "        proj_matrix: A matrix of shape (num_features, num_features) containing the projection matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    # Group data by class\n",
        "    _, num_labels = np.unique(labels, return_counts=True)\n",
        "    labels_idx = np.split(np.argsort(labels), np.cumsum(num_labels)[:-1])\n",
        "    data_class = [data[idx] for idx in labels_idx]\n",
        "    data = data[np.argsort(labels)]\n",
        "\n",
        "    # Initialize eigenvectors variable\n",
        "    eig_vecs = None\n",
        "\n",
        "    # Get sha1 hash of the data and labels\n",
        "    hash = hashlib.sha1()\n",
        "    hash.update(data.tobytes())\n",
        "    hash.update(labels.tobytes())\n",
        "    hash = hash.hexdigest()\n",
        "\n",
        "    # Check if the eigenvectors are cached\n",
        "    if os.path.exists(f\"./.cache/lda_{hash}.npy\"):\n",
        "        eig_vecs = np.load(f\"./.cache/lda_{hash}.npy\")\n",
        "    else:\n",
        "        # Calculate class and overall means\n",
        "        mu_class = [np.mean(data_class[i], axis=0) for i in range(len(data_class))]\n",
        "        mu_all = np.mean(data, axis=0)\n",
        "\n",
        "        # Calculate between-class scatter matrix\n",
        "        s_b = np.zeros((data.shape[1], data.shape[1]))\n",
        "        for i in range(len(mu_class)):\n",
        "            centered_data = (mu_class[i] - mu_all).reshape(1, data.shape[1])\n",
        "            s_b += num_labels[i] * centered_data.T @ centered_data\n",
        "\n",
        "        # Calculate within-class scatter matrix\n",
        "        z_i = np.zeros((data.shape[0], data.shape[1]))\n",
        "        for i in range(len(data_class)):\n",
        "            z_i[labels_idx[i]] = data_class[i] - mu_class[i]\n",
        "        s = z_i.T @ z_i\n",
        "        del z_i\n",
        "        del mu_class\n",
        "\n",
        "        # Compute eigenvectors\n",
        "        # s_inv = la.pinvh(s)\n",
        "        # eig_vals, eig_vecs = la.eig(s_inv @ s_b)\n",
        "        s += np.finfo(np.float32).eps * np.eye(s.shape[0])\n",
        "        s_b += np.finfo(np.float32).eps * np.eye(s_b.shape[0])\n",
        "        eig_vals, eig_vecs = la.eigh(s_b, s)\n",
        "        del s_b\n",
        "        del s\n",
        "        # del s_inv\n",
        "\n",
        "        # Sort eigenvectors by eigenvalues in descending order\n",
        "        idx = eig_vals.argsort()[::-1]\n",
        "        eig_vecs = eig_vecs[:, idx]\n",
        "        eig_vecs = np.real(eig_vecs)\n",
        "\n",
        "        # Cache eigenvectors\n",
        "        if not os.path.exists(\"./.cache\"):\n",
        "            os.makedirs(\"./.cache\")\n",
        "        np.save(f\"./.cache/lda_{hash}.npy\", eig_vecs)\n",
        "\n",
        "    # Return the largest n - 1 eigenvectors where n is the number of classes\n",
        "    eigc = len(num_labels) - 1 if eigc is None else min(eigc, len(eig_vecs))\n",
        "    return eig_vecs[:, :eigc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kEwuIgXfqe-"
      },
      "source": [
        "## Run the Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efR274Vefqe-"
      },
      "outputs": [],
      "source": [
        "proj_matrix = lda(training_data, training_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So8TA7Vqfqe-"
      },
      "source": [
        "## Evaluate the Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmzisdwafqe_"
      },
      "outputs": [],
      "source": [
        "evaluate_model(proj_matrix, training_data, training_labels, testing_data, testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Lqauzdfqe_"
      },
      "source": [
        "# Face vs Non-Face Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgHmEgJVfqe_"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzZPlhtifqe_"
      },
      "outputs": [],
      "source": [
        "# Load both face and non-face data\n",
        "face_data = load_data('./archive')[0]\n",
        "non_face_data = load_data('./non_face')[0]\n",
        "\n",
        "# Randomize the data to avoid bias when splitting\n",
        "np.random.seed(43)\n",
        "np.random.shuffle(face_data)\n",
        "np.random.seed(43)\n",
        "np.random.shuffle(non_face_data)\n",
        "\n",
        "# Equate the number of samples for each class\n",
        "num_samples = min(face_data.shape[0], non_face_data.shape[0])\n",
        "face_data = face_data[:num_samples]\n",
        "non_face_data = non_face_data[:num_samples]\n",
        "\n",
        "# Concatenate the data and create labels\n",
        "data = np.concatenate((face_data, non_face_data))\n",
        "labels = np.concatenate((np.ones(face_data.shape[0]), np.zeros(non_face_data.shape[0])))\n",
        "\n",
        "# Free up memory\n",
        "del face_data\n",
        "del non_face_data\n",
        "\n",
        "# Split the data into training and testing sets with a 1:1 ratio\n",
        "training_data = data[1::2]\n",
        "training_labels = labels[1::2]\n",
        "testing_data = data[::2]\n",
        "testing_labels = labels[::2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opqKc6JvfqfA"
      },
      "source": [
        "## Perform LDA (using **one** eigenvector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zouQ5p3fqfA"
      },
      "outputs": [],
      "source": [
        "proj_matrix = lda(training_data, training_labels, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7QJSsKnfqfB"
      },
      "source": [
        "## Test the Accuracy of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_-5YT5_fqfB"
      },
      "outputs": [],
      "source": [
        "evaluate_model(proj_matrix, training_data, training_labels, testing_data, testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4b0wn4WfqfB"
      },
      "source": [
        "## How Many Dominant Eigenvectors to Use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2GoJBFcfqfC"
      },
      "source": [
        "LDA seeks to maximize the separation between the classes in a lower dimensionality, hence the number of dominant eigenvectors should correspond to the minimum of (number of classes and the original dimensionality), which means in this case one eigenvector could be enough.\n",
        "\n",
        "We can still try using 20, 41 dominant eigenvectors to see if the accuracy improves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THWGMZNjfqfC"
      },
      "outputs": [],
      "source": [
        "def compare_egc(training_data, training_labels, testing_data, testing_labels, egcs):\n",
        "    \"\"\"\n",
        "    Compares the accuracy of the LDA model for different numbers of eigenvectors.\n",
        "\n",
        "    Args:\n",
        "        training_data: A matrix of shape (num_training_samples, num_features) containing the training data.\n",
        "        training_labels: A vector of shape (num_training_samples,) containing the labels of the training data.\n",
        "        testing_data: A matrix of shape (num_testing_samples, num_features) containing the testing data.\n",
        "        testing_labels: A vector of shape (num_testing_samples,) containing the labels of the testing data.\n",
        "        egcs: A list of integers containing the number of eigenvectors to use for the projection matrix.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Initialize the list of accuracies\n",
        "    accuracies = [0] * len(egcs)\n",
        "\n",
        "    # Loop through the list of eigenvector counts\n",
        "    for i, egc in enumerate(egcs):\n",
        "        # Compute the projection matrix\n",
        "        proj_matrix = lda(training_data, training_labels, egc)\n",
        "\n",
        "        # Evaluate the model\n",
        "        print(f\"Evaluating model with {egc} eigenvectors:\")\n",
        "        accuracies[i] = evaluate_model(proj_matrix, training_data, training_labels, testing_data, testing_labels)\n",
        "\n",
        "    # Plot the results\n",
        "    plt.plot(egcs, accuracies)\n",
        "    plt.xlabel(\"Number of Eigenvectors\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy vs. Number of Eigenvectors\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij5HREjMfqfO"
      },
      "outputs": [],
      "source": [
        "# Compare the accuracy of the LDA model for different numbers of eigenvectors\n",
        "compare_egc(training_data, training_labels, testing_data, testing_labels, [1, 21, 40])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOnF-CoMfqfP"
      },
      "source": [
        "## Effect of the Number of Non-Face Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEfWeYjefqfP"
      },
      "outputs": [],
      "source": [
        "def compare_nf_ratio(training_data, training_labels, testing_data, testing_labels, ratios):\n",
        "    \"\"\"\n",
        "    Compares the accuracy of the LDA model for different ratios of non-face to face images.\n",
        "\n",
        "    Args:\n",
        "        training_data: A matrix of shape (num_training_samples, num_features) containing the training data.\n",
        "        training_labels: A vector of shape (num_training_samples,) containing the labels of the training data.\n",
        "        testing_data: A matrix of shape (num_testing_samples, num_features) containing the testing data.\n",
        "        testing_labels: A vector of shape (num_testing_samples,) containing the labels of the testing data.\n",
        "        ratios: A list of floats containing the ratios of non-face to face images to use.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Initialize the list of accuracies\n",
        "    accuracies = [0] * len(ratios)\n",
        "\n",
        "    # Loop through the list of ratios\n",
        "    for i, ratio in enumerate(sorted(ratios, reverse=True)):\n",
        "        # Reduce the number of non-face images to ratio * num_face_images\n",
        "        num_face_images = np.sum(training_labels == 1)\n",
        "        num_non_face_images = np.sum(training_labels == 0)\n",
        "        reduced_amount = num_non_face_images - int(ratio * num_face_images)\n",
        "        training_data = training_data[:-reduced_amount]\n",
        "        training_labels = training_labels[:-reduced_amount]\n",
        "\n",
        "        # Compute the projection matrix\n",
        "        proj_matrix = lda(training_data, training_labels, 1)\n",
        "\n",
        "        # Evaluate the model\n",
        "        print(f\"Evaluating model with {ratio} ratio of non-face to face images:\")\n",
        "        accuracies[i] = evaluate_model(proj_matrix, training_data, training_labels, testing_data, testing_labels)\n",
        "\n",
        "    # Plot the results\n",
        "    plt.plot(ratios, accuracies)\n",
        "    plt.xlabel(\"Ratio of Non-Face to Face Images\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy vs. Ratio of Non-Face to Face Images\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUCOhVMOfqfQ"
      },
      "outputs": [],
      "source": [
        "# Compare the accuracy of the LDA model for different ratios of non-face to face images\n",
        "compare_nf_ratio(training_data, training_labels, testing_data, testing_labels, [0.3, 0.6, 1.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EufffSDOfqfQ"
      },
      "source": [
        "# Effect of Splitting Ratio (Bonus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_HcfyaVfqfR"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1VOrTc0fqfR"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data, labels = load_data('./archive')\n",
        "\n",
        "# Get the indices of the training and testing data\n",
        "# Data will be splitted into training and testing sets with a 7:3 ratio\n",
        "training_indices = np.arange(len(data)) % 10 < 7\n",
        "testing_indices = np.arange(len(data)) % 10 >= 7\n",
        "\n",
        "# Split the data\n",
        "training_data = data[training_indices]\n",
        "training_labels = labels[training_indices]\n",
        "testing_data = data[testing_indices]\n",
        "testing_labels = labels[testing_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jGN0E7BfqfR"
      },
      "source": [
        "## Plot a Random Sample From the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60nRFN29fqfS"
      },
      "outputs": [],
      "source": [
        "print(\"A sample of images from the training set:\")\n",
        "plot_images_samples(training_data, training_labels, 7)\n",
        "\n",
        "print(\"A sample of images from the testing set:\")\n",
        "plot_images_samples(testing_data, testing_labels, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG3vvScafqfS"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z8WZNUDfqfT"
      },
      "outputs": [],
      "source": [
        "# Initialize the list of alpha values\n",
        "alphas = [0.8, 0.85, 0.9, 0.95]\n",
        "\n",
        "# Compute the projection matrices for each alpha\n",
        "proj_matrices = pca(training_data, alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r33g0PUAfqfT"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDLdjAgafqfT"
      },
      "outputs": [],
      "source": [
        "# Evaluate the performance of the k-NN classifier for each alpha\n",
        "for i in range(len(alphas)):\n",
        "  print(f\"Evaluating model with alpha = {alphas[i]}:\")\n",
        "  evaluate_model(proj_matrices[i], training_data, training_labels, testing_data, testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngLfDH2ifqfU"
      },
      "source": [
        "# Compare with Sklearn PCA and LDA (Bonus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzsS0ywafqfU"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQiWX8rKfqfU"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data, labels = load_data('./archive')\n",
        "\n",
        "# Split the data into training and testing sets with a 1:1 ratio\n",
        "training_data = data[1::2]\n",
        "training_labels = labels[1::2]\n",
        "testing_data = data[::2]\n",
        "testing_labels = labels[::2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5LZjUj3fqfV"
      },
      "source": [
        "## Compare PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvVK9WM4fqfV"
      },
      "outputs": [],
      "source": [
        "def compare_pca(training_data, training_labels, testing_data, testing_labels, alphas):\n",
        "    \"\"\"\n",
        "    Compares the accuracy of Sklearn's PCA algorithm with that of our implementation.\n",
        "\n",
        "    Args:\n",
        "        training_data: A matrix of shape (num_training_samples, num_features) containing the training data.\n",
        "        training_labels: A vector of shape (num_training_samples,) containing the labels of the training data.\n",
        "        testing_data: A matrix of shape (num_testing_samples, num_features) containing the testing data.\n",
        "        testing_labels: A vector of shape (num_testing_samples,) containing the labels of the testing data.\n",
        "        alphas: A list of floats containing the alpha values to use.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the list of accuracies\n",
        "    sklearn_accuracies = [0] * len(alphas)\n",
        "    our_accuracies = [0] * len(alphas)\n",
        "\n",
        "    # Loop through the list of alpha values\n",
        "    for i in range(len(alphas)):\n",
        "        # Predict the labels using Sklearn's PCA\n",
        "        sklearn_pca = SKLPCA(n_components=alphas[i])\n",
        "        proj_training_data = sklearn_pca.fit_transform(training_data)\n",
        "        proj_testing_data = sklearn_pca.transform(testing_data)\n",
        "        knn = KNeighborsClassifier(n_neighbors=1)\n",
        "        knn.fit(proj_training_data, training_labels)\n",
        "        y_pred = knn.predict(proj_testing_data)\n",
        "        sklearn_accuracies[i] = np.mean(y_pred == testing_labels)\n",
        "\n",
        "        # Predict the labels using our implementation of PCA\n",
        "        proj_matrix = pca(training_data, [alphas[i]])[0]\n",
        "        proj_training_data = np.dot(training_data, proj_matrix)\n",
        "        proj_testing_data = np.dot(testing_data, proj_matrix)\n",
        "        knn = KNeighborsClassifier(n_neighbors=1)\n",
        "        knn.fit(proj_training_data, training_labels)\n",
        "        y_pred = knn.predict(proj_testing_data)\n",
        "        our_accuracies[i] = np.mean(y_pred == testing_labels)\n",
        "\n",
        "        # Print the results\n",
        "        print(f\"Evaluating model with alpha = {alphas[i]}:\")\n",
        "        print(f\"Sklearn's PCA accuracy: {sklearn_accuracies[i]}\")\n",
        "        print(f\"Our PCA accuracy: {our_accuracies[i]}\")\n",
        "\n",
        "    # Plot the results\n",
        "    plt.plot(alphas, sklearn_accuracies, label=\"Sklearn's PCA\")\n",
        "    plt.plot(alphas, our_accuracies, label=\"Our PCA\")\n",
        "    plt.xlabel(\"Alpha\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy vs. Alpha\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P3ZfKfWfqfW"
      },
      "outputs": [],
      "source": [
        "compare_pca(training_data, training_labels, testing_data, testing_labels, [0.8, 0.85, 0.9, 0.95])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uazPZX1Gfqe9"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}